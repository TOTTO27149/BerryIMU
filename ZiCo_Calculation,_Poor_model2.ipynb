{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyN9ge93GCXE8/+6M6mZls1K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TOTTO27149/BerryIMU/blob/master/ZiCo_Calculation%2C_Poor_model2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting things up and helper functions**"
      ],
      "metadata": {
        "id": "82LYL4cKV3Ak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYt2wb-EXWxM"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Tuple\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq1aoKb4dGzE",
        "outputId": "3aeb2303-94a7-4644-d86d-278a268a2279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConvBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels: int, out_channels: int, is_res: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.same_channels = in_channels == out_channels\n",
        "        self.is_res = is_res\n",
        "\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # If using residual connection\n",
        "        if self.is_res:\n",
        "\n",
        "            x1 = self.conv1(x)\n",
        "            x2 = self.conv2(x1)\n",
        "\n",
        "            # If input and output channels are the same, add residual connection directly\n",
        "            if self.same_channels:\n",
        "                out = x + x2\n",
        "            else:\n",
        "                # If not, apply a 1x1 convolutional layer to match dimensions before adding residual connection\n",
        "                shortcut = nn.Conv2d(x.shape[1], x2.shape[1], kernel_size=1, stride=1, padding=0).to(x.device)\n",
        "                out = shortcut(x) + x2\n",
        "            #print(f\"resconv forward: x {x.shape}, x1 {x1.shape}, x2 {x2.shape}, out {out.shape}\")\n",
        "\n",
        "            # Normalize output tensor\n",
        "            return out / 1.414\n",
        "\n",
        "        # If not using residual connection, return output of second convolutional layer\n",
        "        else:\n",
        "            x1 = self.conv1(x)\n",
        "            x2 = self.conv2(x1)\n",
        "            return x2\n",
        "\n",
        "    # Method to get the number of output channels for this block\n",
        "    def get_out_channels(self):\n",
        "        return self.conv2[0].out_channels\n",
        "\n",
        "    # Method to set the number of output channels for this block\n",
        "    def set_out_channels(self, out_channels):\n",
        "        self.conv1[0].out_channels = out_channels\n",
        "        self.conv2[0].in_channels = out_channels\n",
        "        self.conv2[0].out_channels = out_channels\n",
        "\n",
        "class UnetUp(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UnetUp, self).__init__()\n",
        "\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, 2, 2),\n",
        "            ResidualConvBlock(out_channels, out_channels),\n",
        "            ResidualConvBlock(out_channels, out_channels),\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    ################### ORIGINAL CODE STARTS ###################################\n",
        "    # def forward(self, x, skip):\n",
        "    #     # Concatenate the input tensor x with the skip connection tensor along the channel dimension\n",
        "    #     x = torch.cat((x, skip), 1)\n",
        "    #\n",
        "    #     # Pass the concatenated tensor through the sequential model and return the output\n",
        "    #     x = self.model(x)\n",
        "    ################### ORIGINAL CODE ENDS #####################################\n",
        "\n",
        "    ## NOTICE: I remove the skip connection to impair the model ability [CHANGE 1]\n",
        "    def forward(self, x):\n",
        "        x = torch.cat((x, x), 1)\n",
        "        x = self.model(x)\n",
        "    ## CHANGE 1 ENDS\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class UnetDown(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UnetDown, self).__init__()\n",
        "\n",
        "        layers = [ResidualConvBlock(in_channels, out_channels), ResidualConvBlock(out_channels, out_channels), nn.MaxPool2d(2)]\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class EmbedFC(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim):\n",
        "        super(EmbedFC, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        layers = [\n",
        "            nn.Linear(input_dim, emb_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(emb_dim, emb_dim),\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_dim)\n",
        "        return self.model(x)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sfilename, lfilename, transform, null_context=False):\n",
        "        self.sprites = np.load(sfilename)\n",
        "        self.slabels = np.load(lfilename)\n",
        "        print(f\"sprite shape: {self.sprites.shape}\")\n",
        "        print(f\"labels shape: {self.slabels.shape}\")\n",
        "        self.transform = transform\n",
        "        self.null_context = null_context\n",
        "        self.sprites_shape = self.sprites.shape\n",
        "        self.slabel_shape = self.slabels.shape\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sprites)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.transform:\n",
        "            image = self.transform(self.sprites[idx])\n",
        "            if self.null_context:\n",
        "                label = torch.tensor(0).to(torch.int64)\n",
        "            else:\n",
        "                label = torch.tensor(self.slabels[idx]).to(torch.int64)\n",
        "        return (image, label)\n",
        "\n",
        "    def getshapes(self):\n",
        "        return self.sprites_shape, self.slabel_shape\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                # from [0,255] to range [0.0,1.0]\n",
        "    transforms.Normalize((0.5,), (0.5,))  # range [-1,1]\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "PYbiTWFJbWzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model: U-net**"
      ],
      "metadata": {
        "id": "BKVpPT2GV8Uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContextUnet(nn.Module):\n",
        "    def __init__(self, in_channels, n_feat=256, n_cfeat=10, height=28):  # cfeat - context features\n",
        "        super(ContextUnet, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.n_feat = n_feat\n",
        "        self.n_cfeat = n_cfeat\n",
        "        self.h = height  #assume h == w. must be divisible by 4, so 28,24,20,16...\n",
        "\n",
        "        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=True)\n",
        "\n",
        "        self.down1 = UnetDown(n_feat, n_feat)        # down1 #[10, 256, 8, 8]\n",
        "        self.down2 = UnetDown(n_feat, 2 * n_feat)    # down2 #[10, 256, 4,  4]\n",
        "\n",
        "        self.to_vec = nn.Sequential(nn.AvgPool2d((4)), nn.GELU())\n",
        "\n",
        "        # Embed the timestep and context labels with a one-layer fully connected neural network\n",
        "        self.timeembed1 = EmbedFC(1, 2*n_feat)\n",
        "        self.timeembed2 = EmbedFC(1, 1*n_feat)\n",
        "        self.contextembed1 = EmbedFC(n_cfeat, 2*n_feat)\n",
        "        self.contextembed2 = EmbedFC(n_cfeat, 1*n_feat)\n",
        "\n",
        "        self.up0 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(2 * n_feat, 2 * n_feat, self.h//4, self.h//4), # up-sample\n",
        "            nn.GroupNorm(8, 2 * n_feat), # normalize\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.up1 = UnetUp(4 * n_feat, n_feat)\n",
        "        self.up2 = UnetUp(2 * n_feat, n_feat)\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Conv2d(2 * n_feat, n_feat, 3, 1, 1), # reduce number of feature maps   #in_channels, out_channels, kernel_size, stride=1, padding=0\n",
        "            nn.GroupNorm(8, n_feat), # normalize\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n_feat, self.in_channels, 3, 1, 1), # map to same number of channels as input\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t, c=None): # here it tells how exactly the embedding is performed\n",
        "        \"\"\"\n",
        "        x : (batch, n_feat, h, w) : input image\n",
        "        t : (batch, n_cfeat)      : time step\n",
        "        c : (batch, n_classes)    : context label\n",
        "        \"\"\"\n",
        "\n",
        "        x = self.init_conv(x)\n",
        "        down1 = self.down1(x)       #[10, 256, 8, 8]\n",
        "        down2 = self.down2(down1)   #[10, 256, 4, 4]\n",
        "\n",
        "        hiddenvec = self.to_vec(down2)\n",
        "\n",
        "        if c is None:\n",
        "            c = torch.zeros(x.shape[0], self.n_cfeat).to(x)\n",
        "\n",
        "        cemb1 = self.contextembed1(c).view(-1, self.n_feat * 2, 1, 1)     # (batch, 2*n_feat, 1,1)\n",
        "        temb1 = self.timeembed1(t).view(-1, self.n_feat * 2, 1, 1)\n",
        "        cemb2 = self.contextembed2(c).view(-1, self.n_feat, 1, 1)\n",
        "        temb2 = self.timeembed2(t).view(-1, self.n_feat, 1, 1)\n",
        "        #print(f\"uunet forward: cemb1 {cemb1.shape}. temb1 {temb1.shape}, cemb2 {cemb2.shape}. temb2 {temb2.shape}\")\n",
        "\n",
        "\n",
        "        up1 = self.up0(hiddenvec)\n",
        "\n",
        "        ## NOTICE: I remove the skip connection to impair the model ability [CHANGE 2]\n",
        "\n",
        "        #################### ORIGINAL CODE STARTS ###############################\n",
        "        # up2 = self.up1(cemb1*up1 + temb1, down2)  # add and multiply embeddings\n",
        "        # up3 = self.up2(cemb2*up2 + temb2, down1)\n",
        "        # out = self.out(torch.cat((up3, x), 1))\n",
        "        #################### ORIGINAL CODE ENDS ###############################\n",
        "\n",
        "        ## NOTICE: I remove the connectino for U-net to impair the model ability [CHANGE 2]\n",
        "        up2 = self.up1(cemb1*up1 + temb1)  # add and multiply embeddings\n",
        "        up3 = self.up2(cemb2*up2 + temb2)\n",
        "        out = out = self.out(torch.cat((up3, up3), 1))\n",
        "        ## CHANGE 2 ENDS\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "1x7uSXcpYL5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling**"
      ],
      "metadata": {
        "id": "gWLFR60gfmL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "\n",
        "# diffusion hyperparameters\n",
        "timesteps = 500\n",
        "beta1 = 1e-4 # hyperparameters for DDPM\n",
        "beta2 = 0.02 # hyperparameters for DDPM\n",
        "\n",
        "# network hyperparameters\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device('cpu'))\n",
        "n_feat = 64 # 64 hidden dimension feature\n",
        "n_cfeat = 5 # context vector is of size 5\n",
        "height = 16 # 16x16 image\n",
        "save_dir = '/content/drive/MyDrive/How-Diffusion-Models-Work-main/weights/'\n",
        "saveModel_dir = '/content/drive/MyDrive/How-Diffusion-Models-Work-main/weights/Poor1TrainedByXinda/'"
      ],
      "metadata": {
        "id": "p9UFUISsYVmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct DDPM noise schedule\n",
        "\n",
        "# these parameters are defined in the DDPM paper; all the parameters in the noise scheduler are to determine what levels of noise to apply to the image at a certain time step\n",
        "# specifically, the following are the scaling factors s1, s2, s3 - they are calculated here.\n",
        "b_t = (beta2 - beta1) * torch.linspace(0, 1, timesteps + 1, device=device) + beta1\n",
        "a_t = 1 - b_t\n",
        "ab_t = torch.cumsum(a_t.log(), dim=0).exp()\n",
        "ab_t[0] = 1"
      ],
      "metadata": {
        "id": "UGEORP27YYVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training: initialisation**"
      ],
      "metadata": {
        "id": "mjloxjuYVyTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training hyperparameters\n",
        "batch_size = 100\n",
        "n_epoch = 32\n",
        "lrate=1e-3\n",
        "\n",
        "# load dataset and construct optimizer\n",
        "dataset = CustomDataset(\"/content/drive/MyDrive/How-Diffusion-Models-Work-main/sprites_1788_16x16.npy\", \"/content/drive/MyDrive/How-Diffusion-Models-Work-main/sprite_labels_nc_1788_16x16.npy\", transform, null_context=False)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "\n",
        "# construct model\n",
        "nn_model = ContextUnet(in_channels=3, n_feat=n_feat, n_cfeat=n_cfeat, height=height).to(device)"
      ],
      "metadata": {
        "id": "9L38Rf69Yb6J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c3b9eb-71bf-4c6d-c387-de9978e2491f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sprite shape: (89400, 16, 16, 3)\n",
            "labels shape: (89400, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in nn_model.parameters())\n",
        "print(total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7_JrL22hXbr",
        "outputId": "389bc148-4da2-4118-932b-ef39b39f796a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1480771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training: collect the gradient**"
      ],
      "metadata": {
        "id": "NUPIsZ8jgiCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training without context code\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "piavJophybn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of batches N\n",
        "N = 10\n",
        "Sample_num = 0\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjjTREMWySpj",
        "outputId": "b260eacf-3eba-456d-b039-3a17ef68354a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7cc29dbf8050>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Num_Score = 30\n",
        "\n",
        "ZiCo_Score = []\n",
        "\n",
        "for idx in range(Num_Score):\n",
        "    skip_outer_loop = False  # Initialize flag for skipping the outer loop\n",
        "\n",
        "    # Initialize dictionary to hold gradients for each batch\n",
        "    batch_gradients = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
        "\n",
        "    # helper function: perturbs an image to a specified noise level\n",
        "    def perturb_input(x, t, noise):\n",
        "        return ab_t.sqrt()[t, None, None, None] * x + (1 - ab_t[t, None, None, None]) * noise\n",
        "\n",
        "    # set into train mode\n",
        "    optim = torch.optim.Adam(nn_model.parameters(), lr=3e-4)\n",
        "    nn_model.train()\n",
        "\n",
        "    batch_idx = 0\n",
        "\n",
        "    pbar = tqdm(dataloader, mininterval=2 )\n",
        "    for x, c in pbar:   # x: images  c: context, one-hot encoded vectors\n",
        "\n",
        "        if skip_outer_loop:  # Check the flag before each inner loop iteration\n",
        "            break\n",
        "\n",
        "        if batch_idx >= N:  # Stop after N batches\n",
        "            break\n",
        "\n",
        "        optim.zero_grad()\n",
        "        x = x.to(device)\n",
        "        c = c.to(x)\n",
        "\n",
        "        # randomly mask out c\n",
        "        # Here we create a context mask, with some randomness, we completely mask out the context, so that the model is able to learn generally what a sprite is - this is common for diffusion model.\n",
        "        context_mask = torch.bernoulli(torch.zeros(c.shape[0]) + 0.9).to(device)\n",
        "        c = c * context_mask.unsqueeze(-1)\n",
        "\n",
        "        # perturb data\n",
        "        noise = torch.randn_like(x)\n",
        "        t = torch.randint(1, timesteps + 1, (x.shape[0],)).to(device)\n",
        "        x_pert = perturb_input(x, t, noise)\n",
        "\n",
        "        # use network to recover noise\n",
        "        pred_noise = nn_model(x_pert, t / timesteps, c=c)\n",
        "\n",
        "        # loss is mean squared error between the predicted and true noise\n",
        "        loss = F.mse_loss(pred_noise, noise)\n",
        "        loss.backward()\n",
        "\n",
        "        # Collect gradients\n",
        "        for layer_name, submodule in nn_model.named_children():\n",
        "            flattened_gradients_for_layer = []\n",
        "            for _, param in enumerate(submodule.parameters()):\n",
        "                # Flatten the gradient tensor to a 1D tensor\n",
        "                flat_gradients = torch.abs(param.grad).clone().detach().view(-1)\n",
        "                # Append it to the list for this layer\n",
        "                flattened_gradients_for_layer.append(flat_gradients)\n",
        "\n",
        "            if flattened_gradients_for_layer:  # Check if the list is not empty\n",
        "                # Concatenate all the flattened gradients for this layer into a single 1D tensor\n",
        "                all_flattened_gradients_for_layer = torch.cat(flattened_gradients_for_layer)\n",
        "                # Store this tensor in the dictionary\n",
        "                batch_gradients[batch_idx][layer_name] = all_flattened_gradients_for_layer.tolist()\n",
        "\n",
        "        batch_idx += 1\n",
        "\n",
        "    # Calculate expectation and standard deviation for each parameter\n",
        "    param_stats = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "    num_same = 0\n",
        "\n",
        "\n",
        "    for layer_name in batch_gradients[0]:\n",
        "        if skip_outer_loop:  # Check the flag again before this innermost loop\n",
        "                break\n",
        "\n",
        "        param_idx = 0\n",
        "        for gradient in batch_gradients[0][layer_name]:\n",
        "            all_values = []\n",
        "\n",
        "            for batch_idx in range(N):\n",
        "                if batch_gradients[0][layer_name][param_idx] == batch_gradients[1][layer_name][param_idx]:\n",
        "                    num_same += 1\n",
        "                all_values.append(batch_gradients[batch_idx][layer_name][param_idx])\n",
        "\n",
        "            expectation = np.mean(all_values)\n",
        "            std_dev = np.std(all_values)\n",
        "\n",
        "            param_stats[layer_name][param_idx]['expectation'] = expectation\n",
        "            param_stats[layer_name][param_idx]['std_dev'] = std_dev\n",
        "\n",
        "            if std_dev == 0:\n",
        "                ZiCo_Score.append(f\"Standard deviation for layer {layer_name}, parameter {param_idx} is zero.\")\n",
        "                skip_outer_loop = True  # Set the flag to True\n",
        "                break  # This will break out of the innermost loop\n",
        "\n",
        "            param_idx += 1\n",
        "\n",
        "    if skip_outer_loop:  # Check the flag after exiting the inner loops\n",
        "        continue  # Skip the rest of this outer loop iteration\n",
        "\n",
        "    # Initialize a variable to hold the sum of log(sum_layername) across all layers\n",
        "    ZiCo = 0\n",
        "\n",
        "    # Loop through each layer_name to calculate sum_layername\n",
        "    for layer_name in param_stats:\n",
        "        sum_layername = 0  # Initialize sum_layername for each layer\n",
        "        # print(3)\n",
        "        for param_idx in param_stats[layer_name]:\n",
        "            # Extract the expectation and standard deviation values for each parameter index\n",
        "            expectation = param_stats[layer_name][param_idx]['expectation']\n",
        "            std_dev = param_stats[layer_name][param_idx]['std_dev']\n",
        "            sum_layername += (expectation / std_dev)\n",
        "\n",
        "        # Take the logarithm of sum_layername and add it to ZiCo\n",
        "        ZiCo += np.log(sum_layername)\n",
        "\n",
        "    ZiCo_Score.append(ZiCo)\n",
        "\n",
        "    Sample_num += 1\n",
        "    print(f\"Iteration {Sample_num} has finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er7WsmOZdqPG",
        "outputId": "e85dc184-ea83-406b-b321-1f3c972dc46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:09<13:39,  1.08it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:04,  7.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 2 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:06,  6.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 3 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:01,  7.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 4 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:02<03:03,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 5 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:09,  6.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 6 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:05,  7.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 7 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:00,  7.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 8 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:02<03:03,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 9 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:11,  6.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:02,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 11 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:02,  7.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 12 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:08,  6.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 13 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:54,  5.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 14 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:02,  7.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 15 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:02,  7.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 16 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:01,  7.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 17 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:02,  7.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 18 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:55,  5.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 19 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:03,  7.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 20 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:01,  7.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 21 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:10,  6.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 22 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:45,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 23 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:17,  6.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 24 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:00,  7.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 25 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:02,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 26 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:07,  6.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 27 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:04,  7.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 28 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:02<02:59,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 29 has finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 10/894 [00:01<02:02,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 30 has finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZiCo_Score"
      ],
      "metadata": {
        "id": "LhNp39zLe0I1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a7fbcf-2410-4b0d-832a-2f6c3f820052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[126.6309717794907,\n",
              " 126.59616850635165,\n",
              " 126.65744594667784,\n",
              " 126.75171658740372,\n",
              " 126.76662735653784,\n",
              " 126.59396248492588,\n",
              " 126.67090330474868,\n",
              " 126.5159375882354,\n",
              " 126.71475676498801,\n",
              " 126.52840462546531,\n",
              " 126.6195510285854,\n",
              " 126.7191755851183,\n",
              " 126.64170349953936,\n",
              " 126.56409610434513,\n",
              " 126.59614821570705,\n",
              " 126.62585321538967,\n",
              " 126.78679442382646,\n",
              " 126.70588113369301,\n",
              " 126.62811226822836,\n",
              " 126.6184700657933,\n",
              " 126.65342180420137,\n",
              " 126.74812635916408,\n",
              " 126.59162682568703,\n",
              " 126.76746834491836,\n",
              " 126.68480256769463,\n",
              " 126.64805655767945,\n",
              " 126.73639584790186,\n",
              " 126.57909452074313,\n",
              " 126.66200466903139,\n",
              " 126.62607122341197]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}